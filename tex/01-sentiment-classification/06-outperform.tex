\item \points{1f}

Run your linear predictor with feature extractor {\tt extractCharacterFeatures}.
Experiment with different values of $n$ to see which one produces the smallest
test error.  You should observe that this error is nearly as small as that
produced by word features.  How do you explain this?

Construct a review (one sentence max) in which character $n$-grams probably
outperform word features, and briefly explain why this is so.

{\em Note: You should replace the {\tt featureExtractor} in {\tt test3b2()} in
{\tt grader.py}, i.e., let {\tt featureExtractor =
submission.extractCharacterFeatures(\_\_)} and report your results. Don't forget
to recover {\tt test3b2()} after finishing this question.}
